"""
Camera Module - Nh·∫≠n di·ªán khu√¥n m·∫∑t, m·∫Øt, mi·ªáng
S·ª≠ d·ª•ng OpenCV Haar Cascades
"""

import cv2
import numpy as np
from datetime import datetime
import time
from modules.sound import SoundModule
from modules.email_alert import send_alert_email

class CameraModule:
    """Module x·ª≠ l√Ω camera v√† nh·∫≠n di·ªán khu√¥n m·∫∑t"""
    
    def __init__(self):
        # Kh·ªüi t·∫°o c√°c Haar Cascade classifiers
        self.face_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_frontalface_default.xml'
        )
        self.eye_cascade = cv2.CascadeClassifier(
            cv2.data.haarcascades + 'haarcascade_eye.xml'
        )
        
        # Camera object
        self.cap = None
        self.is_running = False
        
        # Tracking variables cho c·∫£nh b√°o
        self.closed_eyes_frames = 0
        self.no_face_frames = 0
        self.ALERT_THRESHOLD = 20  # 20 frames li√™n ti·∫øp (~0.67 gi√¢y ·ªü 30fps)
        
        # Statistics
        self.total_frames = 0
        self.alert_count = 0
        
    def start_camera(self, camera_id=0):
        """
        Kh·ªüi ƒë·ªông camera
        Args:
            camera_id: ID c·ªßa camera (0 l√† camera m·∫∑c ƒë·ªãnh)
        Returns:
            bool: True n·∫øu kh·ªüi ƒë·ªông th√†nh c√¥ng
        """
        try:
            self.cap = cv2.VideoCapture(camera_id)
            
            if not self.cap.isOpened():
                print(f"Kh√¥ng th·ªÉ m·ªü camera ID: {camera_id}")
                return False
            
            # C·∫•u h√¨nh camera
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, 640)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, 480)
            self.cap.set(cv2.CAP_PROP_FPS, 30)
            
            self.is_running = True
            print("‚úì Camera ƒë√£ s·∫µn s√†ng")
            return True
            
        except Exception as e:
            print(f"L·ªói kh·ªüi ƒë·ªông camera: {str(e)}")
            return False
    
    def detect_features(self, frame):
        """
        Ph√°t hi·ªán khu√¥n m·∫∑t, m·∫Øt v√† ƒë√°nh gi√° tr·∫°ng th√°i
        Args:
            frame: Frame t·ª´ camera (numpy array)
        Returns:
            tuple: (processed_frame, detection_data)
        """
        if frame is None:
            return None, None
        
        # Chuy·ªÉn sang grayscale ƒë·ªÉ x·ª≠ l√Ω nhanh h∆°n
        gray = cv2.cvtColor(frame, cv2.COLOR_BGR2GRAY)
        
        # Ph√°t hi·ªán khu√¥n m·∫∑t
        faces = self.face_cascade.detectMultiScale(
            gray,
            scaleFactor=1.1,
            minNeighbors=5,
            minSize=(80, 80),
            flags=cv2.CASCADE_SCALE_IMAGE
        )
        
        # Kh·ªüi t·∫°o d·ªØ li·ªáu ph√°t hi·ªán
        detection_data = {
            'faces': len(faces),
            'eyes': 0,
            'alert_type': None,  # None, 'no_face', 'closed_eyes', 'drowsy'
            'alert_level': 0,  # 0: OK, 1: Warning, 2: Danger
            'timestamp': datetime.now(),
            'frame_number': self.total_frames
        }
        
        # X·ª≠ l√Ω t·ª´ng khu√¥n m·∫∑t
        for (x, y, w, h) in faces:
            # V·∫Ω h√¨nh ch·ªØ nh·∫≠t cho khu√¥n m·∫∑t
            cv2.rectangle(frame, (x, y), (x+w, y+h), (0, 255, 0), 2)
            cv2.putText(frame, 'Face', (x, y-10),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)
            
            # ROI (Region of Interest) cho m·∫Øt
            roi_gray = gray[y:y+h, x:x+w]
            roi_color = frame[y:y+h, x:x+w]
            
            # Ph√°t hi·ªán m·∫Øt
            eyes = self.eye_cascade.detectMultiScale(
                roi_gray,
                scaleFactor=1.1,
                minNeighbors=10,
                minSize=(20, 20)
            )
            
            detection_data['eyes'] += len(eyes)
            
            # V·∫Ω h√¨nh ch·ªØ nh·∫≠t cho m·∫Øt
            for (ex, ey, ew, eh) in eyes:
                cv2.rectangle(roi_color, (ex, ey), (ex+ew, ey+eh), (255, 0, 0), 2)
                cv2.putText(roi_color, 'Eye', (ex, ey-5),
                           cv2.FONT_HERSHEY_SIMPLEX, 0.4, (255, 0, 0), 1)
            
            # Ph√°t hi·ªán v√πng mi·ªáng (d∆∞·ªõi n·ª≠a khu√¥n m·∫∑t)
            mouth_roi_y = int(h * 0.6)
            mouth_roi = roi_color[mouth_roi_y:h, :]
            
            # V·∫Ω v√πng mi·ªáng ƒë∆°n gi·∫£n
            mouth_x = int(w * 0.3)
            mouth_y = mouth_roi_y + int(h * 0.1)
            mouth_w = int(w * 0.4)
            mouth_h = int(h * 0.15)
            cv2.rectangle(roi_color, 
                         (mouth_x, mouth_y), 
                         (mouth_x + mouth_w, mouth_y + mouth_h), 
                         (0, 0, 255), 2)
            cv2.putText(roi_color, 'Mouth', (mouth_x, mouth_y-5),
                       cv2.FONT_HERSHEY_SIMPLEX, 0.4, (0, 0, 255), 1)
        
        # ƒê√°nh gi√° tr·∫°ng th√°i v√† c·∫£nh b√°o
        detection_data = self._evaluate_driver_state(detection_data)
        
        # V·∫Ω tr·∫°ng th√°i l√™n frame
        self._draw_status(frame, detection_data)
        
        self.total_frames += 1
        return frame, detection_data
    
    def _evaluate_driver_state(self, data):
        """
        ƒê√°nh gi√° tr·∫°ng th√°i t√†i x·∫ø d·ª±a tr√™n d·ªØ li·ªáu ph√°t hi·ªán
        """
        # Kh√¥ng ph√°t hi·ªán khu√¥n m·∫∑t
        if data['faces'] == 0:
            self.no_face_frames += 1
            self.closed_eyes_frames = 0
            
            if self.no_face_frames > self.ALERT_THRESHOLD:
                data['alert_type'] = 'no_face'
                data['alert_level'] = 2
                self.alert_count += 1
            elif self.no_face_frames > self.ALERT_THRESHOLD // 2:
                data['alert_type'] = 'no_face'
                data['alert_level'] = 1
        
        # Ph√°t hi·ªán khu√¥n m·∫∑t nh∆∞ng kh√¥ng c√≥ m·∫Øt (m·∫Øt ƒë√≥ng)
        elif data['faces'] > 0 and data['eyes'] < 2:
            self.closed_eyes_frames += 1
            self.no_face_frames = 0
            
            if self.closed_eyes_frames > self.ALERT_THRESHOLD:
                data['alert_type'] = 'closed_eyes'
                data['alert_level'] = 2
                self.alert_count += 1
            elif self.closed_eyes_frames > self.ALERT_THRESHOLD // 2:
                data['alert_type'] = 'drowsy'
                data['alert_level'] = 1
        
        # Tr·∫°ng th√°i b√¨nh th∆∞·ªùng
        else:
            self.closed_eyes_frames = 0
            self.no_face_frames = 0
            data['alert_level'] = 0
        
        return data
    
    def _draw_status(self, frame, data):
        """V·∫Ω th√¥ng tin tr·∫°ng th√°i l√™n frame"""
        h, w = frame.shape[:2]
        
        # Background cho text
        overlay = frame.copy()
        cv2.rectangle(overlay, (0, 0), (w, 120), (0, 0, 0), -1)
        cv2.addWeighted(overlay, 0.6, frame, 0.4, 0, frame)
        
        # Th√¥ng tin c∆° b·∫£n
        cv2.putText(frame, f"Khuon mat: {data['faces']}", (10, 30),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f"Mat: {data['eyes']}", (10, 60),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.7, (255, 255, 255), 2)
        cv2.putText(frame, f"Frames: {self.total_frames}", (10, 90),
                   cv2.FONT_HERSHEY_SIMPLEX, 0.6, (200, 200, 200), 1)
        
        # C·∫£nh b√°o
        if data['alert_level'] > 0:
            alert_messages = {
                'no_face': 'CANH BAO: Khong phat hien tai xe!',
                'closed_eyes': 'NGUY HIEM: Tai xe dang ngu gat!',
                'drowsy': 'CHU Y: Tai xe co dau hieu buon ngu'
            }
            
            message = alert_messages.get(data['alert_type'], 'CANH BAO!')
            color = (0, 0, 255) if data['alert_level'] == 2 else (0, 165, 255)
            
            # C·∫£nh b√°o n·ªïi b·∫≠t
            cv2.rectangle(frame, (0, h-80), (w, h), color, -1)
            cv2.putText(frame, message, (w//2 - 250, h-40),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.0, (255, 255, 255), 3)
            
            # Bi·ªÉu t∆∞·ª£ng c·∫£nh b√°o
            cv2.circle(frame, (50, h-40), 25, (255, 255, 255), -1)
            cv2.putText(frame, '!', (43, h-25),
                       cv2.FONT_HERSHEY_SIMPLEX, 1.5, color, 3)
    
    def get_frame(self):
        """
        L·∫•y frame hi·ªán t·∫°i t·ª´ camera v√† x·ª≠ l√Ω
        Returns:
            tuple: (processed_frame, detection_data)
        """
        if not self.is_running or self.cap is None:
            return None, None
        
        ret, frame = self.cap.read()
        if not ret:
            print("Kh√¥ng th·ªÉ ƒë·ªçc frame t·ª´ camera")
            return None, None
        
        return self.detect_features(frame)
    
    def get_statistics(self):
        """L·∫•y th·ªëng k√™"""
        return {
            'total_frames': self.total_frames,
            'alert_count': self.alert_count,
            'uptime': time.time()
        }
    
    def release(self):
        """Gi·∫£i ph√≥ng t√†i nguy√™n camera"""
        self.is_running = False
        if self.cap is not None:
            self.cap.release()
        cv2.destroyAllWindows()
        print("‚úì ƒê√£ d·ª´ng camera")


# Test code
if __name__ == "__main__":
    print("Testing Camera Module...")
    camera = CameraModule()
    
    if camera.start_camera():
        print("Nh·∫•n 'q' ƒë·ªÉ tho√°t")
        
        while True:
            frame, data = camera.get_frame()
            
            if frame is not None:
                cv2.imshow('Driver Monitor Test', frame)
                
                if data and data['alert_level'] > 0:
                    print(f"‚ö†Ô∏è  Alert: {data['alert_type']} - Level: {data['alert_level']}")
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        camera.release()
    else:
        print("‚ùå Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông camera")



        # Test code
if __name__ == "__main__":
    print("Testing Camera Module...")
    camera = CameraModule()
    
    # Kh·ªüi t·∫°o module √¢m thanh
    sound = SoundModule()

    # C·∫•u h√¨nh email ng∆∞·ªùi nh·∫≠n
    RECIPIENT_EMAIL = "manager-email@example.com" # Thay b·∫±ng email qu·∫£n l√Ω

    # Bi·∫øn theo d√µi cooldown ƒë·ªÉ tr√°nh spam
    SOUND_COOLDOWN = 5  # Gi√¢y - 5 gi√¢y ph√°t √¢m thanh 1 l·∫ßn
    EMAIL_COOLDOWN = 300 # Gi√¢y - 5 ph√∫t g·ª≠i email 1 l·∫ßn
    
    last_sound_alert = 0
    last_email_alert = 0
    
    if camera.start_camera():
        print("Nh·∫•n 'q' ƒë·ªÉ tho√°t")
        
        while True:
            frame, data = camera.get_frame()
            
            if frame is not None:
                cv2.imshow('Driver Monitor Test', frame)
                
                # ---- T√çCH H·ª¢P C·∫¢NH B√ÅO ----
                current_time = time.time()
                
                if data and data['alert_level'] > 0:
                    # 1. C·∫£nh b√°o √Çm thanh (b·∫•t k·ª≥ c·∫£nh b√°o n√†o)
                    if (current_time - last_sound_alert) > SOUND_COOLDOWN:
                        print("üîä K√≠ch ho·∫°t c·∫£nh b√°o √¢m thanh...")
                        try:
                            # Ch·∫°y √¢m thanh ·ªü thread ri√™ng ƒë·ªÉ kh√¥ng block
                            # (N·∫øu playsound b·ªã treo, c·∫ßn d√πng th∆∞ vi·ªán kh√°c nh∆∞ pygame.mixer)
                            # ƒê∆°n gi·∫£n nh·∫•t l√† g·ªçi tr·ª±c ti·∫øp:
                            sound.play_sound() 
                        except Exception as e:
                            print(f"L·ªói ph√°t √¢m thanh: {e}")
                        last_sound_alert = current_time

                    # 2. C·∫£nh b√°o Email (ch·ªâ khi nguy hi·ªÉm c·∫•p 2)
                    if data['alert_level'] == 2 and (current_time - last_email_alert) > EMAIL_COOLDOWN:
                        print("üìß K√≠ch ho·∫°t g·ª≠i email c·∫£nh b√°o...")
                        subject = f"[NGUY HI·ªÇM] T√†i x·∫ø c√≥ d·∫•u hi·ªáu ng·ªß g·∫≠t!"
                        body = (
                            f"Ph√°t hi·ªán t√†i x·∫ø c√≥ d·∫•u hi·ªáu nguy hi·ªÉm (m√£: {data['alert_type']})\n"
                            f"V√†o l√∫c: {data['timestamp']}\n"
                            f"Vui l√≤ng ki·ªÉm tra ngay l·∫≠p t·ª©c."
                        )
                        # G·ª≠i email (h√†m n√†y ƒë√£ ch·∫°y n·ªÅn, kh√¥ng c·∫ßn thread)
                        send_alert_email(RECIPIENT_EMAIL, subject, body)
                        last_email_alert = current_time
                # -----------------------------
            
            if cv2.waitKey(1) & 0xFF == ord('q'):
                break
        
        camera.release()
    else:
        print("‚ùå Kh√¥ng th·ªÉ kh·ªüi ƒë·ªông camera")